{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010414,
     "end_time": "2021-11-25T13:48:42.626169",
     "exception": false,
     "start_time": "2021-11-25T13:48:42.615755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extract 1-hop Local Subgraphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-25T13:48:42.661431Z",
     "iopub.status.busy": "2021-11-25T13:48:42.660746Z",
     "iopub.status.idle": "2021-11-25T13:48:45.541312Z",
     "shell.execute_reply": "2021-11-25T13:48:45.542398Z",
     "shell.execute_reply.started": "2021-11-09T17:36:58.881764Z"
    },
    "papermill": {
     "duration": 2.906001,
     "end_time": "2021-11-25T13:48:45.543227",
     "exception": false,
     "start_time": "2021-11-25T13:48:42.637226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import sparse\n",
    "import networkx as nx\n",
    "import time\n",
    "from datetime import date\n",
    "import random\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "path = 'scisci-data/'\n",
    "\n",
    "NUM_OF_VERTICES=64719 # number of vertices of the semantic net\n",
    "\n",
    "data_source = path+'CompetitionSet2017_3.pkl'\n",
    "#data_source=path+'TrainSet2014_3.pkl'\n",
    "full_dynamic_graph_sparse,unconnected_vertex_pairs,year_start,years_delta = pickle.load( open( data_source, \"rb\" ) )\n",
    "\n",
    "with open(path+'TrainSet2014_3_solution.pkl', \"rb\" ) as pkl_file:\n",
    "        unconnected_vertex_pairs_solution = pickle.load(pkl_file)\n",
    "        \n",
    "\n",
    "print(data_source+' has '+str(len(full_dynamic_graph_sparse))+' edges between a total of '+str(NUM_OF_VERTICES)+ ' vertices.\\n\\n')\n",
    "print('The goal is to predict which of '+str(len(unconnected_vertex_pairs))+' unconnectedvertex-pairs\\nin unconnected_vertex_pairs will be connected until '+str(year_start+years_delta)+'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-25T13:48:45.572789Z",
     "iopub.status.busy": "2021-11-25T13:48:45.572094Z",
     "iopub.status.idle": "2021-11-25T13:48:45.585239Z",
     "shell.execute_reply": "2021-11-25T13:48:45.585803Z",
     "shell.execute_reply.started": "2021-11-09T17:36:58.957629Z"
    },
    "papermill": {
     "duration": 0.029502,
     "end_time": "2021-11-25T13:48:45.586064",
     "exception": false,
     "start_time": "2021-11-25T13:48:45.556562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unconnected_vertex_pairs_solution[unconnected_vertex_pairs_solution == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010043,
     "end_time": "2021-11-25T13:48:45.607045",
     "exception": false,
     "start_time": "2021-11-25T13:48:45.597002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Construyendo el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-25T13:48:45.645335Z",
     "iopub.status.busy": "2021-11-25T13:48:45.639102Z",
     "iopub.status.idle": "2021-11-25T13:50:09.196071Z",
     "shell.execute_reply": "2021-11-25T13:50:09.195265Z",
     "shell.execute_reply.started": "2021-11-09T17:36:58.966964Z"
    },
    "papermill": {
     "duration": 83.578401,
     "end_time": "2021-11-25T13:50:09.196265",
     "exception": false,
     "start_time": "2021-11-25T13:48:45.617864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_training_data(full_graph,year_start,years_delta,edges_used=10000,vertex_degree_cutoff=10):\n",
    "    \"\"\"\n",
    "    :param full_graph: Full graph, numpy array dim(n,3) [vertex 1, vertex 2, time stamp]\n",
    "    :param year_start: year of graph\n",
    "    :param years_delta: distance for prediction in years (prediction on graph of year_start+years_delta)\n",
    "    :param edges_used: optional filter to create a random subset of edges for rapid prototyping (default: 500,000)\n",
    "    :param vertex_degree_cutoff: optional filter, for vertices in training set having a minimal degree of at least vertex_degree_cutoff  (default: 10)\n",
    "    :return:\n",
    "\n",
    "    all_edge_list: graph of year_start, numpy array dim(n,3)\n",
    "    unconnected_vertex_pairs: potential edges for year_start+years_delta\n",
    "    unconnected_vertex_pairs_solution: numpy array with integers (0=unconnected, 1=connected), solution, length = len(unconnected_vertex_pairs)\n",
    "    \"\"\"\n",
    "\n",
    "    years=[year_start,year_start+years_delta]    #2011 - 2014\n",
    "    day_origin = date(1990,1,1)\n",
    "\n",
    "    all_G=[]\n",
    "    all_edge_lists=[]\n",
    "    all_sparse=[]\n",
    "    for yy in years:\n",
    "        print('    Create Graph for ', yy)\n",
    "        day_curr=date(yy,12,31)\n",
    "        all_edges_curr=full_graph[full_graph[:,2]<(day_curr-day_origin).days]\n",
    "        adj_mat_sparse_curr = sparse.csr_matrix((np.ones(len(all_edges_curr)), \n",
    "                                                 (all_edges_curr[:,0], all_edges_curr[:,1])),\n",
    "                                                shape=(NUM_OF_VERTICES,NUM_OF_VERTICES))\n",
    "        G_curr=nx.from_scipy_sparse_matrix(adj_mat_sparse_curr, \n",
    "                                           parallel_edges=False, create_using=None, \n",
    "                                           edge_attribute='weight')\n",
    "\n",
    "        all_G.append(G_curr)\n",
    "        all_sparse.append(adj_mat_sparse_curr)\n",
    "        all_edge_lists.append(all_edges_curr)\n",
    "\n",
    "        print('    Done: Create Graph for ', yy)\n",
    "        print('    num of edges: ', G_curr.number_of_edges())\n",
    "\n",
    "    all_degs=np.array(all_sparse[0].sum(0))[0]\n",
    "\n",
    "    ## Create all edges to be predicted\n",
    "    all_vertices=np.array(range(NUM_OF_VERTICES))\n",
    "    vertex_large_degs=all_vertices[all_degs>=1] # use only vertices with degrees larger than 10.\n",
    "\n",
    "    unconnected_vertex_pairs=[]\n",
    "    unconnected_vertex_pairs_solution=[]\n",
    "\n",
    "    time_start=time.time()\n",
    "    # agregar aristas con target positivo\n",
    "    day_curr=date(years[0],12,31)\n",
    "    day_ult = date(years[-1],12,31)\n",
    "    all_edges_positives = all_edges_curr[(all_edges_curr[:,2]>(day_curr-day_origin).days)\n",
    "                                         &(all_edges_curr[:,2] < (day_ult-day_origin).days)]\n",
    "    \n",
    "    all_edges_positives = all_edges_positives[np.random.choice(np.array(range(len(all_edges_positives))),\n",
    "                                           6000,replace=False)] # se termina dividiendo por 2 cuando se eliminan nodos con degree<10\n",
    "    \n",
    "    unconnected_vertex_pairs = []\n",
    "    for elem in all_edges_positives:\n",
    "        if(elem[0] in vertex_large_degs) or (elem[1] in vertex_large_degs):\n",
    "            if(not all_G[0].has_edge(elem[0],elem[1])):\n",
    "                if (((elem[0],elem[1]) not in unconnected_vertex_pairs) \n",
    "                    and ((elem[1],elem[0]) not in unconnected_vertex_pairs)):\n",
    "                    unconnected_vertex_pairs.append((elem[0],elem[1]))\n",
    "    \n",
    "    unconnected_vertex_pairs_solution = [1 for elem in unconnected_vertex_pairs]\n",
    "\n",
    "    \n",
    "    while len(unconnected_vertex_pairs)<edges_used:        \n",
    "        v1,v2=random.sample(range(len(all_vertices)), 2)\n",
    "\n",
    "        if (v1!=v2) and (not all_G[0].has_edge(v1,v2)):\n",
    "            if(v1 in vertex_large_degs) or (v2 in vertex_large_degs):\n",
    "                if len(unconnected_vertex_pairs)%10**6==0:\n",
    "                    time_end=time.time()\n",
    "                    print('    edge progress (',time_end-time_start,'sec): ',len(unconnected_vertex_pairs)/10**6,'M/',edges_used/10**6,'M')\n",
    "                    time_start=time.time()\n",
    "                unconnected_vertex_pairs.append((v1,v2))\n",
    "                unconnected_vertex_pairs_solution.append(all_G[1].has_edge(v1,v2))\n",
    "\n",
    "        \n",
    "    print('Number of unconnected vertex pairs for prediction: ', len(unconnected_vertex_pairs_solution))\n",
    "    print('Number of vertex pairs that will be connected: ' , sum(unconnected_vertex_pairs_solution))\n",
    "    print('Ratio of vertex pairs that will be connected: ' , sum(unconnected_vertex_pairs_solution)/len(unconnected_vertex_pairs_solution))\n",
    "    \n",
    "    unconnected_vertex_pairs=np.array(unconnected_vertex_pairs)\n",
    "    unconnected_vertex_pairs_solution=np.array(list(map(int, unconnected_vertex_pairs_solution)))\n",
    "    \n",
    "    \n",
    "    all_edge_list=np.array(all_edge_lists[0]) #todas aristas del aÃ±o input\n",
    "    \n",
    "    return all_edge_list, unconnected_vertex_pairs, unconnected_vertex_pairs_solution\n",
    "\n",
    "\n",
    "vertex_degree_cutoff=1\n",
    "train_dynamic_graph_sparse,train_edges_for_checking,train_edges_solution = (create_training_data(full_dynamic_graph_sparse, \n",
    "                                                                         year_start-years_delta, years_delta, \n",
    "                                                                             vertex_degree_cutoff=vertex_degree_cutoff))\n",
    "\n",
    "\n",
    "adj_mat_sparse_curr_train = sparse.csr_matrix((np.ones(len(train_dynamic_graph_sparse)), \n",
    "                                               (train_dynamic_graph_sparse[:,0], train_dynamic_graph_sparse[:,1])), \n",
    "                                              shape=(NUM_OF_VERTICES,NUM_OF_VERTICES))\n",
    "\n",
    "train_edges_for_checking,train_edges_solution = shuffle(train_edges_for_checking,\n",
    "                                                        train_edges_solution,\n",
    "                                                        random_state=8)\n",
    "\n",
    "\n",
    "#para testear\n",
    "adj_mat_sparse_curr_test = sparse.csr_matrix((np.ones(len(full_dynamic_graph_sparse[:,2])), \n",
    "                                               (full_dynamic_graph_sparse[:,0], full_dynamic_graph_sparse[:,1])), \n",
    "                                              shape=(NUM_OF_VERTICES,NUM_OF_VERTICES))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012144,
     "end_time": "2021-11-25T13:50:09.220640",
     "exception": false,
     "start_time": "2021-11-25T13:50:09.208496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Local Subgraphs Construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-25T13:50:09.252444Z",
     "iopub.status.busy": "2021-11-25T13:50:09.251646Z",
     "iopub.status.idle": "2021-11-25T13:50:09.254217Z",
     "shell.execute_reply": "2021-11-25T13:50:09.253344Z",
     "shell.execute_reply.started": "2021-11-09T17:39:39.807089Z"
    },
    "papermill": {
     "duration": 0.020537,
     "end_time": "2021-11-25T13:50:09.254406",
     "exception": false,
     "start_time": "2021-11-25T13:50:09.233869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def neighbors(fringe, A):\n",
    "    res = set(A[list(fringe)].indices)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-25T13:50:09.292176Z",
     "iopub.status.busy": "2021-11-25T13:50:09.291244Z",
     "iopub.status.idle": "2021-11-25T13:50:10.301406Z",
     "shell.execute_reply": "2021-11-25T13:50:10.302054Z",
     "shell.execute_reply.started": "2021-11-09T17:39:39.831632Z"
    },
    "papermill": {
     "duration": 1.034481,
     "end_time": "2021-11-25T13:50:10.302315",
     "exception": false,
     "start_time": "2021-11-25T13:50:09.267834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def drnl_node_labeling(adj, src, dst):\n",
    "    # Double Radius Node Labeling (DRNL).\n",
    "    src, dst = (dst, src) if src > dst else (src, dst)\n",
    "\n",
    "    idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
    "    adj_wo_src = adj[idx, :][:, idx]\n",
    "\n",
    "    idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
    "    adj_wo_dst = adj[idx, :][:, idx]\n",
    "\n",
    "    dist2src = shortest_path(adj_wo_dst, directed=False, unweighted=True, indices=src)\n",
    "    dist2src = np.insert(dist2src, dst, 0, axis=0)\n",
    "    dist2src = torch.from_numpy(dist2src)\n",
    "\n",
    "    dist2dst = shortest_path(adj_wo_src, directed=False, unweighted=True, indices=dst-1)\n",
    "    dist2dst = np.insert(dist2dst, src, 0, axis=0)\n",
    "    dist2dst = torch.from_numpy(dist2dst)\n",
    "\n",
    "    dist = dist2src + dist2dst\n",
    "    dist_over_2, dist_mod_2 = dist // 2, dist % 2\n",
    "\n",
    "    z = 1 + torch.min(dist2src, dist2dst)\n",
    "    z += dist_over_2 * (dist_over_2 + dist_mod_2 - 1)\n",
    "    z[src] = 1.\n",
    "    z[dst] = 1.\n",
    "    z[torch.isnan(z)] = 0.\n",
    "    z = z.numpy()\n",
    "    z[z>9] = 9\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-25T13:50:10.341496Z",
     "iopub.status.busy": "2021-11-25T13:50:10.340083Z",
     "iopub.status.idle": "2021-11-25T13:50:10.355731Z",
     "shell.execute_reply": "2021-11-25T13:50:10.356333Z",
     "shell.execute_reply.started": "2021-11-09T17:39:41.303878Z"
    },
    "papermill": {
     "duration": 0.039906,
     "end_time": "2021-11-25T13:50:10.356529",
     "exception": false,
     "start_time": "2021-11-25T13:50:10.316623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp\n",
    "def k_hop_subgraph(src, dst, num_hops, A,target,\n",
    "                   max_nodes=None,sample_ratio=0.35):\n",
    "\n",
    "    nodes = [src, dst]\n",
    "    visited = set([src, dst])\n",
    "    fringe = set([src, dst])\n",
    "    for dist in range(1, num_hops+1):\n",
    "        fringe = neighbors(fringe, A)\n",
    "        fringe = fringe - visited\n",
    "        visited = visited.union(fringe)\n",
    "        if sample_ratio < 1.0:\n",
    "            fringe = random.sample(fringe, int(sample_ratio*len(fringe)))\n",
    "        if max_nodes is not None:\n",
    "            if max_nodes < len(fringe):\n",
    "                fringe = random.sample(fringe, max_nodes)\n",
    "        if len(fringe) == 0:\n",
    "            break\n",
    "        nodes = nodes + list(fringe)\n",
    "    \n",
    "    nodes = np.array(nodes)\n",
    "    subgraph = A[nodes, :][:, nodes]\n",
    "\n",
    "    if len(nodes) == 2: # si no hay degree\n",
    "        if target == 1:\n",
    "            target = -1\n",
    "        if target == 0:\n",
    "            target = -2\n",
    "        return subgraph,np.array([1,1]).reshape(-1,1),target\n",
    "    \n",
    "    \n",
    "    node_features = drnl_node_labeling(subgraph.copy(), 0, 1)\n",
    "    \n",
    "    return subgraph,node_features,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-25T13:50:10.383805Z",
     "iopub.status.busy": "2021-11-25T13:50:10.382778Z",
     "iopub.status.idle": "2021-11-25T13:50:10.393504Z",
     "shell.execute_reply": "2021-11-25T13:50:10.394066Z",
     "shell.execute_reply.started": "2021-11-09T17:39:41.328283Z"
    },
    "papermill": {
     "duration": 0.02593,
     "end_time": "2021-11-25T13:50:10.394267",
     "exception": false,
     "start_time": "2021-11-25T13:50:10.368337",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.mkdir(\"train\")\n",
    "lista = []\n",
    "print(\"Generando datos de entrenamiento\")\n",
    "for cont,arista in enumerate(train_edges_for_checking):\n",
    "    A,X,target = k_hop_subgraph(src=arista[0], dst=arista[1],\n",
    "                                num_hops=1,A=adj_mat_sparse_curr_train,\n",
    "                                target=int(train_edges_solution[cont]))\n",
    "    if target < 0:\n",
    "        target = target+2\n",
    "    lista.append(target)\n",
    "    scipy.sparse.save_npz('train/'+str(cont)+\"_adj_V1_train\", A, compressed=True)\n",
    "    np.save('train/'+str(cont)+\"_x_V1_train\", X)\n",
    "\n",
    "\n",
    "    if cont%1000 == 0:\n",
    "        print(str(100*cont/len(train_edges_for_checking))+'%')\n",
    "\n",
    "!tar -zcf train.tar.gz /kaggle/working/train/\n",
    "!rm -R train        \n",
    "\n",
    "lista = np.array(lista)\n",
    "np.save('targets_train',lista)\n",
    "print(\"listo\")\n",
    "print(\"Generando datos de test\")\n",
    "os.mkdir(\"0_test\")\n",
    "cont2 = 0\n",
    "lista = []\n",
    "for cont,arista in enumerate(unconnected_vertex_pairs):\n",
    "    A,X,target = k_hop_subgraph(src=arista[0], dst=arista[1],\n",
    "                num_hops=1,A=adj_mat_sparse_curr_test,\n",
    "                target = unconnected_vertex_pairs_solution[cont])\n",
    "    \n",
    "    lista.append(target)\n",
    "    if target >= 0:\n",
    "        scipy.sparse.save_npz(str(cont2)+'_test/'+str(cont)+\"_adj_V1_test\", A, compressed=True)\n",
    "        np.save(str(cont2)+'_test/'+str(cont)+\"_x_V1_test\", X)\n",
    "        \n",
    "    if cont%100000 == 0:\n",
    "        if cont2 == 0:\n",
    "            !tar -zcf cero.tar.gz /kaggle/working/0_test/\n",
    "            !rm -R 0_test\n",
    "        if cont2 == 1:\n",
    "            !tar -zcf uno.tar.gz /kaggle/working/1_test/\n",
    "            !rm -R 1_test\n",
    "        if cont2 == 2:\n",
    "            !tar -zcf dos.tar.gz /kaggle/working/2_test/\n",
    "            !rm -R 2_test\n",
    "        if cont2 == 3:\n",
    "            !tar -zcf tres.tar.gz /kaggle/working/3_test/\n",
    "            !rm -R 3_test\n",
    "        if cont2 == 4:\n",
    "            !tar -zcf cuatro.tar.gz /kaggle/working/4_test/\n",
    "            !rm -R 4_test\n",
    "        if cont2 == 5:\n",
    "            !tar -zcf cinco.tar.gz /kaggle/working/5_test/\n",
    "            !rm -R 5_test\n",
    "        if cont2 == 6:\n",
    "            !tar -zcf seis.tar.gz /kaggle/working/6_test/\n",
    "            !rm -R 6_test\n",
    "        if cont2 == 7:\n",
    "            !tar -zcf siete.tar.gz /kaggle/working/7_test/\n",
    "            !rm -R 7_test\n",
    "        if cont2 == 8:\n",
    "            !tar -zcf ocho.tar.gz /kaggle/working/8_test/\n",
    "            !rm -R 8_test\n",
    "        if cont2 == 9:\n",
    "            !tar -zcf nueve.tar.gz /kaggle/working/9_test/\n",
    "            !rm -R 9_test\n",
    "        cont2 += 1\n",
    "        os.mkdir(str(cont2)+\"_test\")\n",
    "        print(str(100*cont/len(unconnected_vertex_pairs))+'%')\n",
    "if cont2 == 10:\n",
    "    !tar -zcf diez.tar.gz /kaggle/working/10_test/\n",
    "    !rm -R 10_test\n",
    "\n",
    "lista=np.array(lista)\n",
    "np.save('targets_test',lista)\n",
    "print(\"listo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 97.965456,
   "end_time": "2021-11-25T13:50:11.870785",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-25T13:48:33.905329",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
