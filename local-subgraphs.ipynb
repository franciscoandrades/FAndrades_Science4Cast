{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-25T14:13:25.228813Z",
     "iopub.status.busy": "2021-11-25T14:13:25.223116Z",
     "iopub.status.idle": "2021-11-25T14:13:27.536230Z",
     "shell.execute_reply": "2021-11-25T14:13:27.536811Z",
     "shell.execute_reply.started": "2021-11-09T17:36:58.881764Z"
    },
    "papermill": {
     "duration": 2.329786,
     "end_time": "2021-11-25T14:13:27.537157",
     "exception": false,
     "start_time": "2021-11-25T14:13:25.207371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/scisci-data/CompetitionSet2017_3.pkl has 7652945 edges between a total of 64719 vertices.\n",
      "\n",
      "\n",
      "The goal is to predict which of 1000000 unconnectedvertex-pairs\n",
      "in unconnected_vertex_pairs will be connected until 2020.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import sparse\n",
    "import networkx as nx\n",
    "import time\n",
    "from datetime import date\n",
    "import random\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "path = '../input/scisci-data/' #change this according to your path\n",
    "\n",
    "NUM_OF_VERTICES=64719 # number of vertices of the semantic net\n",
    "\n",
    "data_source = path+'CompetitionSet2017_3.pkl'\n",
    "#data_source=path+'TrainSet2014_3.pkl'\n",
    "full_dynamic_graph_sparse,unconnected_vertex_pairs,year_start,years_delta = pickle.load( open( data_source, \"rb\" ) )\n",
    "\n",
    "with open(path+'TrainSet2014_3_solution.pkl', \"rb\" ) as pkl_file:\n",
    "        unconnected_vertex_pairs_solution = pickle.load(pkl_file)\n",
    "        \n",
    "\n",
    "print(data_source+' has '+str(len(full_dynamic_graph_sparse))+' edges between a total of '+str(NUM_OF_VERTICES)+ ' vertices.\\n\\n')\n",
    "print('The goal is to predict which of '+str(len(unconnected_vertex_pairs))+' unconnectedvertex-pairs\\nin unconnected_vertex_pairs will be connected until '+str(year_start+years_delta)+'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-25T14:13:27.558539Z",
     "iopub.status.busy": "2021-11-25T14:13:27.556881Z",
     "iopub.status.idle": "2021-11-25T14:13:27.568472Z",
     "shell.execute_reply": "2021-11-25T14:13:27.568983Z",
     "shell.execute_reply.started": "2021-11-09T17:36:58.957629Z"
    },
    "papermill": {
     "duration": 0.023805,
     "end_time": "2021-11-25T14:13:27.569178",
     "exception": false,
     "start_time": "2021-11-25T14:13:27.545373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unconnected_vertex_pairs_solution[unconnected_vertex_pairs_solution == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007214,
     "end_time": "2021-11-25T14:13:27.583966",
     "exception": false,
     "start_time": "2021-11-25T14:13:27.576752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Construyendo el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-25T14:13:27.603597Z",
     "iopub.status.busy": "2021-11-25T14:13:27.602538Z",
     "iopub.status.idle": "2021-11-25T14:14:29.761306Z",
     "shell.execute_reply": "2021-11-25T14:14:29.761826Z",
     "shell.execute_reply.started": "2021-11-09T17:36:58.966964Z"
    },
    "papermill": {
     "duration": 62.170805,
     "end_time": "2021-11-25T14:14:29.762061",
     "exception": false,
     "start_time": "2021-11-25T14:13:27.591256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Create Graph for  2014\n",
      "    Done: Create Graph for  2014\n",
      "    num of edges:  1843253\n",
      "    Create Graph for  2017\n",
      "    Done: Create Graph for  2017\n",
      "    num of edges:  5568240\n",
      "Number of unconnected vertex pairs for prediction:  10000\n",
      "Number of vertex pairs that will be connected:  4692\n",
      "Ratio of vertex pairs that will be connected:  0.4692\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_training_data(full_graph,year_start,years_delta,edges_used=10000,vertex_degree_cutoff=10):\n",
    "    \"\"\"\n",
    "    :param full_graph: Full graph, numpy array dim(n,3) [vertex 1, vertex 2, time stamp]\n",
    "    :param year_start: year of graph\n",
    "    :param years_delta: distance for prediction in years (prediction on graph of year_start+years_delta)\n",
    "    :param edges_used: optional filter to create a random subset of edges for rapid prototyping (default: 500,000)\n",
    "    :param vertex_degree_cutoff: optional filter, for vertices in training set having a minimal degree of at least vertex_degree_cutoff  (default: 10)\n",
    "    :return:\n",
    "\n",
    "    all_edge_list: graph of year_start, numpy array dim(n,3)\n",
    "    unconnected_vertex_pairs: potential edges for year_start+years_delta\n",
    "    unconnected_vertex_pairs_solution: numpy array with integers (0=unconnected, 1=connected), solution, length = len(unconnected_vertex_pairs)\n",
    "    \"\"\"\n",
    "\n",
    "    years=[year_start,year_start+years_delta]    #2011 - 2014\n",
    "    day_origin = date(1990,1,1)\n",
    "\n",
    "    all_G=[]\n",
    "    all_edge_lists=[]\n",
    "    all_sparse=[]\n",
    "    for yy in years:\n",
    "        print('    Create Graph for ', yy)\n",
    "        day_curr=date(yy,12,31)\n",
    "        all_edges_curr=full_graph[full_graph[:,2]<(day_curr-day_origin).days]\n",
    "        adj_mat_sparse_curr = sparse.csr_matrix((np.ones(len(all_edges_curr)), \n",
    "                                                 (all_edges_curr[:,0], all_edges_curr[:,1])),\n",
    "                                                shape=(NUM_OF_VERTICES,NUM_OF_VERTICES))\n",
    "        G_curr=nx.from_scipy_sparse_matrix(adj_mat_sparse_curr, \n",
    "                                           parallel_edges=False, create_using=None, \n",
    "                                           edge_attribute='weight')\n",
    "\n",
    "        all_G.append(G_curr)\n",
    "        all_sparse.append(adj_mat_sparse_curr)\n",
    "        all_edge_lists.append(all_edges_curr)\n",
    "\n",
    "        print('    Done: Create Graph for ', yy)\n",
    "        print('    num of edges: ', G_curr.number_of_edges())\n",
    "\n",
    "    all_degs=np.array(all_sparse[0].sum(0))[0]\n",
    "\n",
    "    ## Create all edges to be predicted\n",
    "    all_vertices=np.array(range(NUM_OF_VERTICES))\n",
    "    vertex_large_degs=all_vertices[all_degs>=1] # use only vertices with degrees larger than 10.\n",
    "\n",
    "    unconnected_vertex_pairs=[]\n",
    "    unconnected_vertex_pairs_solution=[]\n",
    "\n",
    "    time_start=time.time()\n",
    "    # agregar aristas con target positivo\n",
    "    day_curr=date(years[0],12,31)\n",
    "    day_ult = date(years[-1],12,31)\n",
    "    all_edges_positives = all_edges_curr[(all_edges_curr[:,2]>(day_curr-day_origin).days)\n",
    "                                         &(all_edges_curr[:,2] < (day_ult-day_origin).days)]\n",
    "    \n",
    "    all_edges_positives = all_edges_positives[np.random.choice(np.array(range(len(all_edges_positives))),\n",
    "                                           6000,replace=False)] # se termina dividiendo por 2 cuando se eliminan nodos con degree<10\n",
    "    \n",
    "    unconnected_vertex_pairs = []\n",
    "    for elem in all_edges_positives:\n",
    "        if(elem[0] in vertex_large_degs) or (elem[1] in vertex_large_degs):\n",
    "            if(not all_G[0].has_edge(elem[0],elem[1])):\n",
    "                if (((elem[0],elem[1]) not in unconnected_vertex_pairs) \n",
    "                    and ((elem[1],elem[0]) not in unconnected_vertex_pairs)):\n",
    "                    unconnected_vertex_pairs.append((elem[0],elem[1]))\n",
    "    \n",
    "    unconnected_vertex_pairs_solution = [1 for elem in unconnected_vertex_pairs]\n",
    "\n",
    "    \n",
    "    while len(unconnected_vertex_pairs)<edges_used:        \n",
    "        v1,v2=random.sample(range(len(all_vertices)), 2)\n",
    "\n",
    "        if (v1!=v2) and (not all_G[0].has_edge(v1,v2)):\n",
    "            if(v1 in vertex_large_degs) or (v2 in vertex_large_degs):\n",
    "                if len(unconnected_vertex_pairs)%10**6==0:\n",
    "                    time_end=time.time()\n",
    "                    print('    edge progress (',time_end-time_start,'sec): ',len(unconnected_vertex_pairs)/10**6,'M/',edges_used/10**6,'M')\n",
    "                    time_start=time.time()\n",
    "                unconnected_vertex_pairs.append((v1,v2))\n",
    "                unconnected_vertex_pairs_solution.append(all_G[1].has_edge(v1,v2))\n",
    "\n",
    "        \n",
    "    print('Number of unconnected vertex pairs for prediction: ', len(unconnected_vertex_pairs_solution))\n",
    "    print('Number of vertex pairs that will be connected: ' , sum(unconnected_vertex_pairs_solution))\n",
    "    print('Ratio of vertex pairs that will be connected: ' , sum(unconnected_vertex_pairs_solution)/len(unconnected_vertex_pairs_solution))\n",
    "    \n",
    "    unconnected_vertex_pairs=np.array(unconnected_vertex_pairs)\n",
    "    unconnected_vertex_pairs_solution=np.array(list(map(int, unconnected_vertex_pairs_solution)))\n",
    "    \n",
    "    \n",
    "    all_edge_list=np.array(all_edge_lists[0]) #todas aristas del aÃ±o input\n",
    "    \n",
    "    return all_edge_list, unconnected_vertex_pairs, unconnected_vertex_pairs_solution\n",
    "\n",
    "\n",
    "vertex_degree_cutoff=1\n",
    "train_dynamic_graph_sparse,train_edges_for_checking,train_edges_solution = (create_training_data(full_dynamic_graph_sparse, \n",
    "                                                                         year_start-years_delta, years_delta, \n",
    "                                                                             vertex_degree_cutoff=vertex_degree_cutoff))\n",
    "\n",
    "\n",
    "adj_mat_sparse_curr_train = sparse.csr_matrix((np.ones(len(train_dynamic_graph_sparse)), \n",
    "                                               (train_dynamic_graph_sparse[:,0], train_dynamic_graph_sparse[:,1])), \n",
    "                                              shape=(NUM_OF_VERTICES,NUM_OF_VERTICES))\n",
    "\n",
    "train_edges_for_checking,train_edges_solution = shuffle(train_edges_for_checking,\n",
    "                                                        train_edges_solution,\n",
    "                                                        random_state=8)\n",
    "\n",
    "\n",
    "#para testear\n",
    "adj_mat_sparse_curr_test = sparse.csr_matrix((np.ones(len(full_dynamic_graph_sparse[:,2])), \n",
    "                                               (full_dynamic_graph_sparse[:,0], full_dynamic_graph_sparse[:,1])), \n",
    "                                              shape=(NUM_OF_VERTICES,NUM_OF_VERTICES))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008308,
     "end_time": "2021-11-25T14:14:29.779233",
     "exception": false,
     "start_time": "2021-11-25T14:14:29.770925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Construir Subgrafos locales\n",
    "current = 100.000, 1-hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-25T14:14:29.802479Z",
     "iopub.status.busy": "2021-11-25T14:14:29.801792Z",
     "iopub.status.idle": "2021-11-25T14:14:29.804732Z",
     "shell.execute_reply": "2021-11-25T14:14:29.804258Z",
     "shell.execute_reply.started": "2021-11-09T17:39:39.807089Z"
    },
    "papermill": {
     "duration": 0.01699,
     "end_time": "2021-11-25T14:14:29.804872",
     "exception": false,
     "start_time": "2021-11-25T14:14:29.787882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def neighbors(fringe, A):\n",
    "    res = set(A[list(fringe)].indices)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-25T14:14:29.832329Z",
     "iopub.status.busy": "2021-11-25T14:14:29.831453Z",
     "iopub.status.idle": "2021-11-25T14:14:30.760149Z",
     "shell.execute_reply": "2021-11-25T14:14:30.760729Z",
     "shell.execute_reply.started": "2021-11-09T17:39:39.831632Z"
    },
    "papermill": {
     "duration": 0.947467,
     "end_time": "2021-11-25T14:14:30.760947",
     "exception": false,
     "start_time": "2021-11-25T14:14:29.813480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def drnl_node_labeling(adj, src, dst):\n",
    "    # Double Radius Node Labeling (DRNL).\n",
    "    src, dst = (dst, src) if src > dst else (src, dst)\n",
    "\n",
    "    idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
    "    adj_wo_src = adj[idx, :][:, idx]\n",
    "\n",
    "    idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
    "    adj_wo_dst = adj[idx, :][:, idx]\n",
    "\n",
    "    dist2src = shortest_path(adj_wo_dst, directed=False, unweighted=True, indices=src)\n",
    "    dist2src = np.insert(dist2src, dst, 0, axis=0)\n",
    "    dist2src = torch.from_numpy(dist2src)\n",
    "\n",
    "    dist2dst = shortest_path(adj_wo_src, directed=False, unweighted=True, indices=dst-1)\n",
    "    dist2dst = np.insert(dist2dst, src, 0, axis=0)\n",
    "    dist2dst = torch.from_numpy(dist2dst)\n",
    "\n",
    "    dist = dist2src + dist2dst\n",
    "    dist_over_2, dist_mod_2 = dist // 2, dist % 2\n",
    "\n",
    "    z = 1 + torch.min(dist2src, dist2dst)\n",
    "    z += dist_over_2 * (dist_over_2 + dist_mod_2 - 1)\n",
    "    z[src] = 1.\n",
    "    z[dst] = 1.\n",
    "    z[torch.isnan(z)] = 0.\n",
    "    z = z.numpy()\n",
    "    z[z>9] = 9\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-25T14:14:30.794601Z",
     "iopub.status.busy": "2021-11-25T14:14:30.793791Z",
     "iopub.status.idle": "2021-11-25T14:14:30.797071Z",
     "shell.execute_reply": "2021-11-25T14:14:30.797568Z",
     "shell.execute_reply.started": "2021-11-09T17:39:41.303878Z"
    },
    "papermill": {
     "duration": 0.027281,
     "end_time": "2021-11-25T14:14:30.797767",
     "exception": false,
     "start_time": "2021-11-25T14:14:30.770486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp\n",
    "def k_hop_subgraph(src, dst, num_hops, A,target,\n",
    "                   max_nodes=None,sample_ratio=0.35):\n",
    "\n",
    "    nodes = [src, dst]\n",
    "    visited = set([src, dst])\n",
    "    fringe = set([src, dst])\n",
    "    for dist in range(1, num_hops+1):\n",
    "        fringe = neighbors(fringe, A)\n",
    "        fringe = fringe - visited\n",
    "        visited = visited.union(fringe)\n",
    "        if sample_ratio < 1.0:\n",
    "            fringe = random.sample(fringe, int(sample_ratio*len(fringe)))\n",
    "        if max_nodes is not None:\n",
    "            if max_nodes < len(fringe):\n",
    "                fringe = random.sample(fringe, max_nodes)\n",
    "        if len(fringe) == 0:\n",
    "            break\n",
    "        nodes = nodes + list(fringe)\n",
    "    \n",
    "    nodes = np.array(nodes)\n",
    "    subgraph = A[nodes, :][:, nodes]\n",
    "\n",
    "    if len(nodes) == 2: # si no hay degree\n",
    "        if target == 1:\n",
    "            target = -1\n",
    "        if target == 0:\n",
    "            target = -2\n",
    "        return subgraph,np.array([1,1]).reshape(-1,1),target\n",
    "    \n",
    "    \n",
    "    node_features = drnl_node_labeling(subgraph.copy(), 0, 1)\n",
    "    \n",
    "    return subgraph,node_features,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-25T14:14:30.820868Z",
     "iopub.status.busy": "2021-11-25T14:14:30.819829Z",
     "iopub.status.idle": "2021-11-25T15:59:52.605238Z",
     "shell.execute_reply": "2021-11-25T15:59:52.606008Z",
     "shell.execute_reply.started": "2021-11-09T17:39:41.328283Z"
    },
    "papermill": {
     "duration": 6321.799877,
     "end_time": "2021-11-25T15:59:52.606930",
     "exception": false,
     "start_time": "2021-11-25T14:14:30.807053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando datos de entrenamiento\n",
      "0.0%\n",
      "10.0%\n",
      "20.0%\n",
      "30.0%\n",
      "40.0%\n",
      "50.0%\n",
      "60.0%\n",
      "70.0%\n",
      "80.0%\n",
      "90.0%\n",
      "tar: Removing leading `/' from member names\r\n",
      "listo\n",
      "Generando datos de test\n",
      "tar: Removing leading `/' from member names\r\n",
      "0.0%\n",
      "tar: Removing leading `/' from member names\r\n",
      "10.0%\n",
      "tar: Removing leading `/' from member names\r\n",
      "20.0%\n",
      "tar: Removing leading `/' from member names\r\n",
      "30.0%\n",
      "tar: Removing leading `/' from member names\r\n",
      "40.0%\n",
      "tar: Removing leading `/' from member names\r\n",
      "50.0%\n",
      "tar: Removing leading `/' from member names\r\n",
      "60.0%\n",
      "tar: Removing leading `/' from member names\r\n",
      "70.0%\n",
      "tar: Removing leading `/' from member names\r\n",
      "80.0%\n",
      "tar: Removing leading `/' from member names\r\n",
      "90.0%\n",
      "tar: Removing leading `/' from member names\r\n",
      "listo\n"
     ]
    }
   ],
   "source": [
    "os.mkdir(\"train\")\n",
    "lista = []\n",
    "print(\"Generando datos de entrenamiento\")\n",
    "for cont,arista in enumerate(train_edges_for_checking):\n",
    "    A,X,target = k_hop_subgraph(src=arista[0], dst=arista[1],\n",
    "                                num_hops=1,A=adj_mat_sparse_curr_train,\n",
    "                                target=int(train_edges_solution[cont]))\n",
    "    if target < 0:\n",
    "        target = target+2\n",
    "    lista.append(target)\n",
    "    scipy.sparse.save_npz('train/'+str(cont)+\"_adj_V1_train\", A, compressed=True)\n",
    "    np.save('train/'+str(cont)+\"_x_V1_train\", X)\n",
    "\n",
    "\n",
    "    if cont%1000 == 0:\n",
    "        print(str(100*cont/len(train_edges_for_checking))+'%')\n",
    "\n",
    "!tar -zcf train.tar.gz /kaggle/working/train/\n",
    "!rm -R train        \n",
    "\n",
    "lista = np.array(lista)\n",
    "np.save('targets_train',lista)\n",
    "print(\"listo\")\n",
    "print(\"Generando datos de test\")\n",
    "os.mkdir(\"0_test\")\n",
    "cont2 = 0\n",
    "lista = []\n",
    "for cont,arista in enumerate(unconnected_vertex_pairs):\n",
    "    A,X,target = k_hop_subgraph(src=arista[0], dst=arista[1],\n",
    "                num_hops=1,A=adj_mat_sparse_curr_test,\n",
    "                target = unconnected_vertex_pairs_solution[cont])\n",
    "    \n",
    "    lista.append(target)\n",
    "    if target >= 0:\n",
    "        scipy.sparse.save_npz(str(cont2)+'_test/'+str(cont)+\"_adj_V1_test\", A, compressed=True)\n",
    "        np.save(str(cont2)+'_test/'+str(cont)+\"_x_V1_test\", X)\n",
    "        \n",
    "    if cont%100000 == 0:\n",
    "        if cont2 == 0:\n",
    "            !tar -zcf cero.tar.gz /kaggle/working/0_test/\n",
    "            !rm -R 0_test\n",
    "        if cont2 == 1:\n",
    "            !tar -zcf uno.tar.gz /kaggle/working/1_test/\n",
    "            !rm -R 1_test\n",
    "        if cont2 == 2:\n",
    "            !tar -zcf dos.tar.gz /kaggle/working/2_test/\n",
    "            !rm -R 2_test\n",
    "        if cont2 == 3:\n",
    "            !tar -zcf tres.tar.gz /kaggle/working/3_test/\n",
    "            !rm -R 3_test\n",
    "        if cont2 == 4:\n",
    "            !tar -zcf cuatro.tar.gz /kaggle/working/4_test/\n",
    "            !rm -R 4_test\n",
    "        if cont2 == 5:\n",
    "            !tar -zcf cinco.tar.gz /kaggle/working/5_test/\n",
    "            !rm -R 5_test\n",
    "        if cont2 == 6:\n",
    "            !tar -zcf seis.tar.gz /kaggle/working/6_test/\n",
    "            !rm -R 6_test\n",
    "        if cont2 == 7:\n",
    "            !tar -zcf siete.tar.gz /kaggle/working/7_test/\n",
    "            !rm -R 7_test\n",
    "        if cont2 == 8:\n",
    "            !tar -zcf ocho.tar.gz /kaggle/working/8_test/\n",
    "            !rm -R 8_test\n",
    "        if cont2 == 9:\n",
    "            !tar -zcf nueve.tar.gz /kaggle/working/9_test/\n",
    "            !rm -R 9_test\n",
    "        cont2 += 1\n",
    "        os.mkdir(str(cont2)+\"_test\")\n",
    "        print(str(100*cont/len(unconnected_vertex_pairs))+'%')\n",
    "if cont2 == 10:\n",
    "    !tar -zcf diez.tar.gz /kaggle/working/10_test/\n",
    "    !rm -R 10_test\n",
    "\n",
    "lista=np.array(lista)\n",
    "np.save('targets_test',lista)\n",
    "print(\"listo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6396.446894,
   "end_time": "2021-11-25T15:59:54.036070",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-25T14:13:17.589176",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
